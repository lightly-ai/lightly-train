{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightly Train - Semantic Segmentation\n",
    "\n",
    "This notebook demonstrates how to use LightlyTrain for semantic segmentarion using the [EoMT](https://arxiv.org/abs/2503.19108) model. See the [semantic segmentation docs](https://docs.lightly.ai/train/stable/quick_start.html) for more details.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lightly-ai/lightly-train/blob/main/examples/notebooks/semantic_segmentation.ipynb)\n",
    "\n",
    "> **Important**: When running on Google Colab make sure to select a GPU runtime for faster processing. You can do this by going to `Runtime` > `Change runtime type` and selecting a GPU hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightly-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**: LightlyTrain is officially supported on\n",
    "> - Linux: CPU or CUDA\n",
    "> - MacOS: CPU only\n",
    "> - Windows (experimental): CPU or CUDA\n",
    "> \n",
    "> We are planning to support MPS for MacOS.\n",
    "> \n",
    "> Check the [installation instructions](https://docs.lightly.ai/train/stable/installation.html) for more details on installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "You can directly start with LightlyTrain's model checkpoints fine-tuned on the [COCO-Stuff](https://arxiv.org/abs/1612.03716) dataset for inference. Check our [docs](https://docs.lightly.ai/train/stable/semantic_segmentation.html) for the benchmark results of these checkpoints.\n",
    "\n",
    "We provide the checkpoints shown in the table below. Click the corresponding link to download the model weights.\n",
    "\n",
    "\n",
    "Download an example image with the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!wget -O cat.jpg https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly_train\n",
    "\n",
    "model = lightly_train.load_model_from_checkpoint(\n",
    "    \"/Users/yutong/Documents/FPS/checkpoints/250910_dinov3_eomt_vits16_ade20k.ckpt\",  # \"/path/to/checkpoint/file.ckpt\"\n",
    "    device=\"cpu\",\n",
    ")\n",
    "masks = model.predict(\"cat.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [data guide](https://docs.lightly.ai/train/stable/semantic_segmentation.html#data) for more information on supported data formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune\n",
    "\n",
    "Once the data is ready, you can fine-tune the model like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The final model is exported to `out/my_experiment/exported_models/exported_last.pt` in\n",
    "the default format of the used library. It can directly be used for\n",
    "fine-tuning. See [export format](https://docs.lightly.ai/train/stable/export.html#format) for more information on how to export\n",
    "models to other formats or on how to export intermediate checkpoints.\n",
    "\n",
    "While the trained model has already learned good representations of the images, it\n",
    "cannot yet make any predictions for tasks such as classification, detection, or\n",
    "segmentation. To solve these tasks, the model needs to be fine-tuned on a labeled\n",
    "dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
