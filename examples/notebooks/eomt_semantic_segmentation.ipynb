{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightlyTrain - Semantic Segmentation with DINOv3 EoMT\n",
    "\n",
    "This notebook demonstrates how to use LightlyTrain for semantic segmentarion using the [EoMT](https://arxiv.org/abs/2503.19108) model. See the [semantic segmentation docs](https://docs.lightly.ai/train/stable/quick_start.html) for more details.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lightly-ai/lightly-train/blob/main/examples/notebooks/semantic_segmentation.ipynb)\n",
    "\n",
    "> **Important**: When running on Google Colab make sure to select a GPU runtime for faster processing. You can do this by going to `Runtime` > `Change runtime type` and selecting a GPU hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightly-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**: LightlyTrain is officially supported on\n",
    "> - Linux: CPU or CUDA\n",
    "> - MacOS: CPU only\n",
    "> - Windows (experimental): CPU or CUDA\n",
    "> \n",
    "> We are planning to support MPS for MacOS.\n",
    "> \n",
    "> Check the [installation instructions](https://docs.lightly.ai/train/stable/installation.html) for more details on installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using LightlyTrain's Model Weights\n",
    "\n",
    "You can directly start with LightlyTrain's state-of-the-art [EoMT](https://arxiv.org/abs/2503.19108) model with [DINOv3](https://github.com/facebookresearch/dinov3) backbones trained on the [COCO-Stuff](https://arxiv.org/abs/1612.03716) dataset for inference. \n",
    "\n",
    "As an example, you can download the ViT-S/16 weights with the command below. Check our [docs](https://docs.lightly.ai/train/stable/semantic_segmentation.html) for all of the available model weights and the corresponding benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O lightlytrain_dinov3_eomt_vits16_cocostuff.pt https://lightly-train-checkpoints.s3.us-east-1.amazonaws.com/dinov3_eomt/lightlytrain_dinov3_eomt_vits16_cocostuff.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the model weights, we download an example image for inference with the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O cat.jpg https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the model weights with LightlyTrain's `load_model_from_checkpoint` function and do inference on the example image with the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly_train\n",
    "\n",
    "model = lightly_train.load_model_from_checkpoint(\n",
    "    \"lightlytrain_dinov3_eomt_vits16_cocostuff.pt\",\n",
    "    device=\"cpu\",  # or \"cuda\" if you have a GPU available\n",
    ")\n",
    "masks = model.predict(\"cat.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the mask to see if it makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(masks.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! Using LightlyTrain's EoMT model weights for inference is as simple as the above example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
